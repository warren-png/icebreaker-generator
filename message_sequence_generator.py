"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MESSAGE SEQUENCE GENERATOR - V27.5 (PAIN POINTS 100% DYNAMIQUES)
Modifications V27.5 :
- generate_dynamic_pain_point() : extraction compÃ©tences rares via Claude
- get_relevant_pain_point() : 100% dynamique, plus de fallback config.py
- generate_message_2() : utilise compÃ©tences rares + reformulation obligatoire
- Prompts renforcÃ©s : interdiction termes gÃ©nÃ©riques, respect expÃ©rience
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import anthropic
import os
import re 
from datetime import datetime, timedelta
from config import COMPANY_INFO, OUTCOMES_DETAILED

# Imports utilitaires
from prospection_utils.logger import log_event, log_error
from prospection_utils.cost_tracker import tracker
from prospection_utils.validator import validate_and_report

ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

if not ANTHROPIC_API_KEY:
    raise ValueError("âŒ ANTHROPIC_API_KEY non trouvÃ©e")


# ========================================
# FILTRAGE HOOKS LINKEDIN - V27.4 ROBUSTE
# ========================================

def filter_recent_posts(posts, max_age_months=3, max_posts=5):
    """
    Filtre les posts LinkedIn pour ne garder que ceux <3 mois
    VERSION V27.4 : Parsing dates ROBUSTE multi-format + fallback intelligent
    """
    if not posts or posts == "NOT_FOUND":
        return []
    
    if not isinstance(posts, list):
        return []
    
    cutoff_date = datetime.now() - timedelta(days=max_age_months * 30)
    recent_posts = []
    posts_without_date = []
    
    for post in posts:
        if not isinstance(post, dict):
            continue
            
        # Chercher la date dans plusieurs champs possibles
        post_date_str = (
            post.get('date') or 
            post.get('postedDate') or 
            post.get('timestamp') or
            post.get('publishedAt') or
            post.get('created_at') or
            ''
        )
        
        if not post_date_str:
            # Pas de date â†’ garder pour fallback
            posts_without_date.append(post)
            continue
        
        # Parser la date avec plusieurs formats
        post_date = None
        date_formats = [
            '%Y-%m-%d',
            '%Y-%m-%dT%H:%M:%S',
            '%Y-%m-%dT%H:%M:%S.%fZ',
            '%Y-%m-%dT%H:%M:%SZ',
            '%d/%m/%Y',
            '%d-%m-%Y',
            '%Y/%m/%d',
            '%B %d, %Y',  # "January 15, 2026"
            '%b %d, %Y',  # "Jan 15, 2026"
        ]
        
        for fmt in date_formats:
            try:
                # Tronquer Ã  10 caractÃ¨res pour formats date seule
                date_to_parse = str(post_date_str)
                if fmt in ['%Y-%m-%d', '%d/%m/%Y', '%d-%m-%Y', '%Y/%m/%d']:
                    date_to_parse = date_to_parse[:10]
                
                post_date = datetime.strptime(date_to_parse, fmt)
                break
            except (ValueError, TypeError):
                continue
        
        # Essayer de parser les dates relatives ("il y a 2 jours", "2d", "3w")
        if not post_date:
            relative_date = parse_relative_date(str(post_date_str))
            if relative_date:
                post_date = relative_date
        
        # VÃ©rifier si la date est rÃ©cente
        if post_date and post_date >= cutoff_date:
            recent_posts.append(post)
        elif post_date:
            log_event('post_filtered_old', {
                'date': str(post_date_str),
                'parsed': post_date.strftime('%Y-%m-%d') if post_date else 'N/A',
                'cutoff': cutoff_date.strftime('%Y-%m-%d')
            })
    
    # Si aucun post rÃ©cent mais des posts sans date â†’ prendre les premiers (risque assumÃ©)
    if not recent_posts and posts_without_date:
        log_event('using_posts_without_date', {
            'count': min(max_posts, len(posts_without_date)),
            'reason': 'No dated posts found within cutoff'
        })
        recent_posts = posts_without_date[:max_posts]
    
    # Trier par date dÃ©croissante et limiter
    def get_sort_date(p):
        d = p.get('date') or p.get('postedDate') or p.get('timestamp') or '1900-01-01'
        return str(d)
    
    recent_posts = sorted(recent_posts, key=get_sort_date, reverse=True)[:max_posts]
    
    log_event('posts_filtered_v27_4', {
        'total_input': len(posts),
        'recent_output': len(recent_posts),
        'without_date': len(posts_without_date),
        'cutoff_date': cutoff_date.strftime('%Y-%m-%d')
    })
    
    return recent_posts


def parse_relative_date(date_str):
    """
    Parse les dates relatives LinkedIn ("2d", "1w", "3mo", "il y a 2 jours")
    VERSION V27.4 : Support multi-langue
    """
    if not date_str:
        return None
    
    date_str_lower = date_str.lower().strip()
    now = datetime.now()
    
    # Patterns anglais
    patterns_en = [
        (r'(\d+)\s*d(?:ay)?s?\s*ago', 'days'),
        (r'(\d+)\s*w(?:eek)?s?\s*ago', 'weeks'),
        (r'(\d+)\s*mo(?:nth)?s?\s*ago', 'months'),
        (r'(\d+)\s*h(?:our)?s?\s*ago', 'hours'),
        (r'(\d+)d\b', 'days'),
        (r'(\d+)w\b', 'weeks'),
        (r'(\d+)mo\b', 'months'),
        (r'(\d+)h\b', 'hours'),
    ]
    
    # Patterns franÃ§ais
    patterns_fr = [
        (r'il y a (\d+)\s*jour', 'days'),
        (r'il y a (\d+)\s*semaine', 'weeks'),
        (r'il y a (\d+)\s*mois', 'months'),
        (r'il y a (\d+)\s*heure', 'hours'),
    ]
    
    all_patterns = patterns_en + patterns_fr
    
    for pattern, unit in all_patterns:
        match = re.search(pattern, date_str_lower)
        if match:
            value = int(match.group(1))
            if unit == 'hours':
                return now - timedelta(hours=value)
            elif unit == 'days':
                return now - timedelta(days=value)
            elif unit == 'weeks':
                return now - timedelta(weeks=value)
            elif unit == 'months':
                return now - timedelta(days=value * 30)
    
    return None


# ========================================
# DÃ‰TECTION SECTEUR - V27.4 ENRICHIE
# ========================================

def detect_company_sector(job_posting_data):
    """
    DÃ©tecte le secteur de l'entreprise
    VERSION V27.4 : Keywords enrichis + detection sans API call
    """
    if not job_posting_data:
        return 'general'
    
    text = f"{job_posting_data.get('title', '')} {job_posting_data.get('description', '')}".lower()
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DÃ‰TECTION PAR MOTS-CLÃ‰S (PRIORITÃ‰)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    sector_keywords = {
        'banking': [
            'banque', 'bank', 'bancaire', 'banking', 'cib', 'retail banking',
            'private banking', 'bpce', 'bnp', 'sociÃ©tÃ© gÃ©nÃ©rale', 'crÃ©dit agricole',
            'crÃ©dit mutuel', 'lcl', 'caisse d\'Ã©pargne', 'natixis', 'hsbc',
            'banque palatine', 'banque populaire'
        ],
        'insurance': [
            'assurance', 'insurance', 'mutuelle', 'iard', 'prÃ©voyance',
            'solvabilitÃ©', 'solvency', 'actuariat', 'actuariel', 'sinistre',
            'cnp', 'axa', 'allianz', 'generali', 'groupama', 'maif', 'macif',
            'covÃ©a', 'ag2r', 'malakoff', 'kereis', 'camca'
        ],
        'logistics_transport': [
            'logistique', 'logistics', 'supply chain', 'transport', 'freight',
            'fret', 'entrepÃ´t', 'warehouse', 'distribution', 'livraison',
            'geodis', 'dhl', 'fedex', 'ups', 'kuehne', 'db schenker',
            'ceva logistics', 'xpo', 'stef', 'id logistics', 'fm logistic',
            '166 pays', '120 pays', 'rÃ©seau mondial', 'hub logistique'
        ],
        'manufacturing': [
            'industrie', 'industriel', 'manufacturing', 'production', 'usine',
            'factory', 'fabrication', 'sites de production', 'atelier',
            'tarkett', 'michelin', 'renault', 'psa', 'stellantis', 'safran',
            'airbus', 'saint-gobain', 'schneider', 'legrand', 'valeo',
            '35 sites', '50 usines', 'sites industriels'
        ],
        'engineering': [
            'ingÃ©nierie', 'engineering', 'btp', 'construction', 'infrastructure',
            'travaux publics', 'gÃ©nie civil', 'bureau d\'Ã©tudes',
            'egis', 'vinci', 'bouygues', 'eiffage', 'colas', 'spie',
            'artelia', 'setec', 'systra', 'arcadis', 'aecom',
            'concession', 'autoroute', 'pont', 'tunnel'
        ],
        'retail': [
            'retail', 'distribution', 'grande distribution', 'magasin',
            'commerce', 'enseigne', 'point de vente', 'rÃ©seau de vente',
            'carrefour', 'auchan', 'leclerc', 'intermarchÃ©', 'casino',
            'fnac', 'darty', 'decathlon', 'leroy merlin', 'ikea'
        ],
        'fintech': [
            'fintech', 'nÃ©obanque', 'neobank', 'payment', 'paiement',
            'crypto', 'blockchain', 'startup', 'scale-up', 'licorne',
            'memo bank', 'qonto', 'lydia', 'revolut', 'n26', 'alan',
            'pennylane', 'payfit', 'spendesk', 'swile'
        ],
        'gaming': [
            'jeu vidÃ©o', 'video game', 'gaming', 'game studio', 'Ã©diteur de jeux',
            'ubisoft', 'activision', 'electronic arts', 'ea', 'gameloft',
            'don\'t nod', 'focus entertainment', 'nacon', 'bigben'
        ],
        'services': [
            'conseil', 'consulting', 'cabinet', 'services professionnels',
            'audit externe', 'expertise comptable', 'commissariat aux comptes',
            'big 4', 'big four', 'deloitte', 'ey', 'kpmg', 'pwc', 'mazars',
            'grant thornton', 'bdo', 'rsm'
        ]
    }
    
    # Scorer chaque secteur
    sector_scores = {sector: 0 for sector in sector_keywords}
    
    for sector, keywords in sector_keywords.items():
        for keyword in keywords:
            if keyword in text:
                # Bonus si dans le nom d'entreprise (plus fiable)
                company_name = job_posting_data.get('company', '').lower()
                if keyword in company_name:
                    sector_scores[sector] += 3
                else:
                    sector_scores[sector] += 1
    
    # Trouver le secteur dominant
    max_score = max(sector_scores.values())
    
    if max_score >= 2:
        detected_sector = max(sector_scores.items(), key=lambda x: x[1])[0]
        log_event('sector_detected_v27_4', {
            'sector': detected_sector,
            'score': max_score,
            'all_scores': {k: v for k, v in sector_scores.items() if v > 0}
        })
        return detected_sector
    
    log_event('sector_fallback_general', {'reason': 'No sector keywords found'})
    return 'general'


# ========================================
# EXTRACTION OUTILS - V27.4 ENRICHIE
# ========================================

def extract_all_keywords_from_job(job_posting_data):
    """
    Ã‰TAPE 1 : Extraction brute de TOUS les mots-clÃ©s potentiels
    VERSION V27.4 : Patterns enrichis
    """
    if not job_posting_data:
        return {'acronyms': [], 'capitalized': [], 'technical': []}
    
    job_text = f"{job_posting_data.get('title', '')} {job_posting_data.get('description', '')}"
    
    # 1. ACRONYMES (2-10 lettres majuscules)
    acronyms = re.findall(r'\b[A-Z]{2,10}\b', job_text)
    
    # 2. MOTS CAPITALISÃ‰S (noms propres, outils)
    capitalized = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', job_text)
    
    # 3. EXPRESSIONS ENTRE PARENTHÃˆSES (souvent des listes d'outils)
    in_parens = re.findall(r'\(([^)]+)\)', job_text)
    technical_terms = []
    for content in in_parens:
        items = [item.strip() for item in content.split(',')]
        technical_terms.extend(items)
    
    # 4. PATTERNS SPÃ‰CIFIQUES V27.4
    # SAP BFC, SAP BPC, Power BI, etc.
    compound_tools = re.findall(r'\b(?:SAP|Power|Microsoft)\s+[A-Z][a-zA-Z]*\b', job_text)
    technical_terms.extend(compound_tools)
    
    return {
        'acronyms': list(set(acronyms)),
        'capitalized': list(set(capitalized)),
        'technical': list(set(technical_terms))
    }


def filter_real_tools(extracted_keywords):
    """
    Ã‰TAPE 2 : Filtrage pour ne garder QUE les vrais outils
    VERSION V27.4 : Liste enrichie SAP BFC, Power Query, TCD
    """
    
    # LISTE BLANCHE : Outils connus avec certitude
    KNOWN_TOOLS = {
        # EPM / Planning
        'Pigment', 'Jedox', 'Lucanet', 'Tagetik', 'Anaplan', 'Hyperion', 
        'OneStream', 'Board', 'Prophix', 'IBM Planning Analytics', 'TM1',
        
        # ERP / SAP
        'SAP', 'SAP BFC', 'SAP BPC', 'SAP S/4HANA', 'SAP FI', 'SAP CO',
        'SAP FICO', 'SAP ECC', 'SAP R/3',
        
        # ERP Autres
        'Oracle', 'Oracle EPM', 'Oracle HFM', 'Sage', 'Sage X3', 'Sage 100',
        'Dynamics', 'Dynamics 365', 'NetSuite', 'Infor', 'Cegid', 'Navision',
        
        # BI / Analytics
        'Tableau', 'Qlik', 'QlikView', 'Qlik Sense', 'Spotfire', 'Looker', 
        'Microstrategy', 'Power BI', 'PowerBI', 'Business Objects', 'BO',
        'Cognos', 'SSRS', 'SSIS', 'Alteryx',
        
        # Langages / Data
        'Python', 'SQL', 'VBA', 'R', 'SAS', 'SPSS', 'Stata',
        
        # Office / ProductivitÃ©
        'Excel', 'Power Query', 'Power Pivot', 'PowerQuery', 'TCD',
        'Access', 'Macro', 'Macros Excel',
        
        # Consolidation
        'HFM', 'Hyperion Financial Management', 'FC', 'Magnitude',
        'Sigma Conso', 'Talentia', 'Caseware',
        
        # Autres outils mÃ©tier
        'Coupa', 'Ariba', 'Concur', 'Workday', 'Salesforce', 'Kyriba',
        'Blackline', 'Trintech', 'Cadency', 'FloQast', 'Vena',
        
        # Audit
        'ACL', 'IDEA', 'TeamMate', 'AuditBoard', 'Galvanize',
        
        # TrÃ©sorerie
        'Kyriba', 'FIS', 'Finastra', 'Calypso', 'Murex', 'Summit'
    }
    
    # LISTE NOIRE : Faux positifs Ã  exclure systÃ©matiquement
    EXCLUDE_LIST = {
        # GÃ©ographie
        'USA', 'UK', 'France', 'Paris', 'Europe', 'Germany', 'Spain',
        'Lyon', 'Marseille', 'Bordeaux', 'Toulouse', 'Nantes', 'Lille',
        
        # RÃ´les / Titres
        'CEO', 'CFO', 'COO', 'CTO', 'DAF', 'RAF', 'DRH', 'CDO', 'CMO',
        'Manager', 'Director', 'Head', 'Chief', 'VP', 'Senior', 'Junior',
        
        # Contrats
        'CDI', 'CDD', 'VIE', 'Stage', 'Interim', 'Alternance',
        
        # Indicateurs / KPI
        'KPI', 'ROI', 'EBITDA', 'CAPEX', 'OPEX', 'SLA', 'NPS', 'MRR', 'ARR',
        'CA', 'PNL', 'P&L', 'BS', 'CF',
        
        # Organisations
        'ETI', 'PME', 'TPE', 'SME', 'BU', 'CODIR', 'COMEX', 'CSE',
        'GIE', 'SAS', 'SA', 'SARL',
        
        # DÃ©partements
        'IT', 'HR', 'RH', 'FTE', 'R&D', 'RD', 'DSI', 'DG', 'DAF',
        
        # Normes (pas des outils)
        'IFRS', 'GAAP', 'SOX', 'COSO', 'IIA', 'ISA',
        
        # Certifications (pas des outils)
        'PMP', 'SAFe', 'Scrum', 'Agile', 'PRINCE2', 'CIA', 'CPA', 'ACCA',
        'DSCG', 'DEC', 'CISA', 'CISM',
        
        # Divers
        'RTT', 'CV', 'PDF', 'EUR', 'USD', 'GBP', 'RER', 'RATP', 'SNCF',
        'Groupe', 'Group', 'Company', 'International', 'Global',
        'CDG', 'LBP', 'BNP', 'SG'  # Entreprises, pas outils
    }
    
    detected_tools = []
    
    # Collecter tous les mots-clÃ©s
    all_keywords = (
        extracted_keywords.get('acronyms', []) + 
        extracted_keywords.get('capitalized', []) + 
        extracted_keywords.get('technical', [])
    )
    
    for keyword in all_keywords:
        keyword_clean = keyword.strip()
        
        # Ignorer vide ou trop court
        if not keyword_clean or len(keyword_clean) < 2:
            continue
        
        # Si dans liste blanche â†’ garder
        if keyword_clean in KNOWN_TOOLS:
            if keyword_clean not in detected_tools:
                detected_tools.append(keyword_clean)
        
        # Si dans liste noire â†’ ignorer
        elif keyword_clean.upper() in EXCLUDE_LIST or keyword_clean in EXCLUDE_LIST:
            continue
        
        # Cas spÃ©ciaux composÃ©s
        elif keyword_clean.startswith('SAP ') or keyword_clean.startswith('Power '):
            if keyword_clean not in detected_tools:
                detected_tools.append(keyword_clean)
    
    # Post-traitement : fusionner "Power" + "BI" en "Power BI"
    if 'Power' in detected_tools and 'BI' in detected_tools:
        detected_tools.remove('Power')
        detected_tools.remove('BI')
        if 'Power BI' not in detected_tools:
            detected_tools.append('Power BI')
    
    # DÃ©dupliquer
    detected_tools = list(set(detected_tools))
    
    log_event('tools_filtered_v27_4', {
        'raw_count': len(all_keywords),
        'filtered_count': len(detected_tools),
        'tools': detected_tools
    })
    
    return detected_tools


# ========================================
# EXTRACTION CERTIFICATIONS - V27.4 ENRICHIE
# ========================================

def extract_certifications_and_norms(job_posting_data):
    """
    DÃ©tecte les certifications et normes mÃ©tier mentionnÃ©es
    VERSION V27.4 : Liste enrichie CIA, IIA, COSO, SolvabilitÃ© II
    """
    if not job_posting_data:
        return []
    
    text = f"{job_posting_data.get('title', '')} {job_posting_data.get('description', '')}".lower()
    
    certifications = {
        # Audit
        'cia': 'CIA',
        ' cia ': 'CIA',  # Avec espaces pour Ã©viter faux positifs
        'certified internal auditor': 'CIA',
        'cpai': 'CPAI',
        'cisa': 'CISA',
        'cism': 'CISM',
        'crma': 'CRMA',
        'cfe': 'CFE',
        
        # Normes Audit
        'normes iia': 'normes IIA',
        'standards iia': 'normes IIA',
        'iia standards': 'normes IIA',
        ' iia': 'normes IIA',
        'coso': 'COSO',
        'cadre coso': 'COSO',
        
        # ComptabilitÃ©
        'dscg': 'DSCG',
        'dec': 'DEC',
        'diplÃ´me d\'expertise comptable': 'DEC',
        'cpa': 'CPA',
        'acca': 'ACCA',
        'cma': 'CMA',
        
        # Normes Comptables
        'ifrs': 'normes IFRS',
        'normes ifrs': 'normes IFRS',
        'gaap': 'normes GAAP',
        'us gaap': 'normes US GAAP',
        'french gaap': 'French GAAP',
        'sox': 'SOX',
        'sarbanes': 'SOX',
        
        # Assurance
        'solvabilitÃ© ii': 'SolvabilitÃ© II',
        'solvabilitÃ© 2': 'SolvabilitÃ© II',
        'solvency ii': 'SolvabilitÃ© II',
        'solvency 2': 'SolvabilitÃ© II',
        
        # Project Management
        'pmp': 'PMP',
        'prince2': 'PRINCE2',
        'safe': 'SAFe',
        'scrum master': 'Scrum Master',
        'psm': 'PSM',
        'csm': 'CSM',
        
        # Finance
        'cfa': 'CFA',
        'frm': 'FRM',
        'amf': 'certification AMF'
    }
    
    detected = []
    for cert_key, cert_name in certifications.items():
        if cert_key in text:
            if cert_name not in detected:
                detected.append(cert_name)
    
    log_event('certifications_detected_v27_4', {
        'count': len(detected),
        'certifications': detected
    })
    
    return detected


# ========================================
# DÃ‰TECTION MÃ‰TIER - V27.4 PRIORITÃ‰ TITRE
# ========================================

def detect_job_category(prospect_data, job_posting_data):
    """
    DÃ©tecte automatiquement la catÃ©gorie mÃ©tier du prospect
    VERSION V27.4 : PRIORITÃ‰ TITRE > DESCRIPTION + exclusions contextuelles
    """
    
    # Ã‰TAPE 1 : Extraire TITRE seul (prioritaire)
    job_title = ""
    if job_posting_data:
        job_title = str(job_posting_data.get('title', '')).lower()
    
    # Ã‰TAPE 2 : Extraire description (secondaire)
    job_desc = ""
    if job_posting_data:
        job_desc = str(job_posting_data.get('description', '')).lower()
    
    # Ã‰TAPE 3 : Headline prospect (tertiaire)
    headline = f"{prospect_data.get('headline', '')} {prospect_data.get('title', '')}".lower()
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DÃ‰TECTION SUR TITRE UNIQUEMENT (PRIORITÃ‰ ABSOLUE)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Comptable / ComptabilitÃ© (AVANT audit car "comptable" est plus spÃ©cifique)
    if any(word in job_title for word in ['comptable', 'accountant', 'accounting']):
        # EXCLUSION : "comptable" dans titre mais "consolidation" aussi â†’ consolidation
        if 'consolidation' in job_title or 'consolidateur' in job_title:
            return 'consolidation'
        return 'comptabilite'
    
    # Audit
    if any(word in job_title for word in ['audit', 'auditeur', 'auditor']):
        return 'audit'
    
    # Consolidation
    if any(word in job_title for word in ['consolidation', 'consolidateur', 'consolidator']):
        return 'consolidation'
    
    # ContrÃ´le de gestion
    if any(word in job_title for word in ['contrÃ´le de gestion', 'controle de gestion', 'contrÃ´leur de gestion', 'controller', 'business controller']):
        return 'controle_gestion'
    
    # FP&A
    if any(word in job_title for word in ['fp&a', 'fpa', 'financial planning', 'fpna']):
        return 'fpna'
    
    # DAF / CFO
    if any(word in job_title for word in ['daf', 'directeur administratif', 'cfo', 'chief financial', 'directeur financier']):
        return 'daf'
    
    # RAF
    if any(word in job_title for word in ['raf', 'responsable administratif']):
        return 'raf'
    
    # Data / IA
    if any(word in job_title for word in ['data officer', 'ia officer', 'ai officer', 'data & ia', 'chief data', 'cdo']):
        return 'data_ia'
    
    # EPM
    if any(word in job_title for word in ['epm', 'anaplan', 'hyperion', 'tagetik']):
        return 'epm'
    
    # BI / Data
    if any(word in job_title for word in ['bi ', 'business intelligence', ' data ', 'analytics']):
        return 'bi_data'
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SI TITRE NON CONCLUANT â†’ DESCRIPTION (avec exclusions)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Nettoyer la description des mentions contextuelles
    desc_cleaned = job_desc
    
    # Exclure "ou audit", "contrÃ´les de niveau 2", etc.
    contextual_exclusions = [
        r'\bou audit\b',
        r'\baudit externe\b',
        r'\bcontrÃ´les? de niveau \d\b',
        r'\brelation avec.*audit\b',
        r'\ben collaboration avec.*audit\b',
        r'\baudit interne et externe\b'
    ]
    
    for pattern in contextual_exclusions:
        desc_cleaned = re.sub(pattern, '', desc_cleaned, flags=re.IGNORECASE)
    
    # Maintenant chercher dans description nettoyÃ©e
    if any(word in desc_cleaned for word in ['comptable', 'comptabilitÃ©', 'accounting']) and 'audit' not in job_title:
        return 'comptabilite'
    
    if any(word in desc_cleaned for word in ['auditeur', 'audit interne', 'internal audit']):
        return 'audit'
    
    if any(word in desc_cleaned for word in ['consolidation', 'ifrs 10', 'normes ifrs']):
        return 'consolidation'
    
    if any(word in desc_cleaned for word in ['contrÃ´le de gestion', 'business controller']):
        return 'controle_gestion'
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # FALLBACK : HEADLINE PROSPECT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    if any(word in headline for word in ['daf', 'cfo', 'directeur financier']):
        return 'daf'
    elif any(word in headline for word in ['audit']):
        return 'audit'
    elif any(word in headline for word in ['comptab']):
        return 'comptabilite'
    elif any(word in headline for word in ['contrÃ´l']):
        return 'controle_gestion'
    
    return 'general'


# ========================================
# PAIN POINTS - V27.5 EXTRACTION DYNAMIQUE
# ========================================

def generate_dynamic_pain_point(job_posting_data, job_category):
    """
    VERSION V27.5 : GÃ©nÃ¨re un pain point PERSONNALISÃ‰ basÃ© sur la fiche de poste
    Extrait les compÃ©tences RARES via Claude et construit un pain point spÃ©cifique
    """
    if not job_posting_data:
        return None
    
    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
    
    job_title = job_posting_data.get('title', 'N/A')
    job_desc = job_posting_data.get('description', '')[:1500]
    
    prompt = f"""Analyse cette fiche de poste et extrais les compÃ©tences RARES qui rendent ce recrutement difficile.

TITRE : {job_title}
DESCRIPTION : {job_desc}

MISSION : Identifier les 2-3 compÃ©tences TECHNIQUES SPÃ‰CIFIQUES qui sont :
1. Explicitement mentionnÃ©es dans la fiche
2. Rares sur le marchÃ© (combinaison inhabituelle)
3. Pas des soft skills gÃ©nÃ©riques (pas "rigueur", "autonomie", "communication")

EXEMPLES DE COMPÃ‰TENCES RARES :
- "rÃ©assurance acceptÃ©e et cÃ©dÃ©e" (comptabilitÃ© assurance)
- "consolidation IFRS multi-entitÃ©s" (consolidation)
- "provisions techniques et arrÃªtÃ©s trimestriels" (comptabilitÃ© technique)
- "audit supply chain multi-sites" (audit logistique)
- "EPM Anaplan et conduite du changement" (EPM)

FORMAT DE RÃ‰PONSE (JSON uniquement, sans texte avant/aprÃ¨s) :
{{
  "competences_rares": ["compÃ©tence 1", "compÃ©tence 2", "compÃ©tence 3"],
  "pain_point_short": "phrase courte dÃ©crivant le dÃ©fi de recrutement (15-20 mots max)",
  "pain_point_context": "phrase plus longue expliquant pourquoi c'est difficile Ã  trouver (25-35 mots)"
}}

RÃˆGLES :
- Utilise UNIQUEMENT les termes EXACTS de la fiche
- JAMAIS inventer de compÃ©tences non mentionnÃ©es
- JAMAIS utiliser "rigueur", "agilitÃ©", "dynamisme", "croissance"
- Le pain point doit mentionner au moins 2 compÃ©tences rares extraites"""

    try:
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=500,
            messages=[{"role": "user", "content": prompt}]
        )
        
        tracker.track(message.usage, 'generate_dynamic_pain_point')
        result = message.content[0].text.strip()
        
        # Parser le JSON
        import json
        
        # Nettoyer les backticks markdown si prÃ©sents
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', result, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_obj_match = re.search(r'(\{.*?\})', result, re.DOTALL)
            if json_obj_match:
                json_str = json_obj_match.group(1)
            else:
                json_str = result
        
        parsed = json.loads(json_str)
        
        pain_point = {
            'short': parsed.get('pain_point_short', ''),
            'context': parsed.get('pain_point_context', ''),
            'competences_rares': parsed.get('competences_rares', [])
        }
        
        log_event('dynamic_pain_point_generated', {
            'job_title': job_title,
            'competences_rares': pain_point['competences_rares'],
            'pain_point_short': pain_point['short']
        })
        
        return pain_point
        
    except Exception as e:
        log_error('dynamic_pain_point_error', str(e), {'job_title': job_title})
        return None


def get_relevant_pain_point(job_category, job_posting_data):
    """
    VERSION V27.5 : Pain point 100% DYNAMIQUE extrait de la fiche
    Plus de fallback sur config.py
    """
    
    # Ã‰TAPE 1 : Extraction dynamique OBLIGATOIRE
    if job_posting_data:
        dynamic_pain_point = generate_dynamic_pain_point(job_posting_data, job_category)
        if dynamic_pain_point and dynamic_pain_point.get('short'):
            return dynamic_pain_point
    
    # Ã‰TAPE 2 : Fallback MINIMAL si pas de fiche ou extraction Ã©chouÃ©e
    # Pain point neutre qui force l'analyse de la fiche dans le prompt
    log_event('pain_point_fallback_minimal', {
        'job_category': job_category,
        'has_job_posting': bool(job_posting_data)
    })
    
    return {
        'short': f"trouver le bon profil pour ce poste de {job_category}",
        'context': "DifficultÃ© Ã  identifier des candidats qui correspondent prÃ©cisÃ©ment aux exigences spÃ©cifiques de ce poste.",
        'competences_rares': []
    }


def get_relevant_outcomes(job_category, max_outcomes=2):
    """RÃ©cupÃ¨re les outcomes pertinents"""
    outcomes = OUTCOMES_DETAILED.get(job_category, OUTCOMES_DETAILED['general'])
    return outcomes[:max_outcomes]


# ========================================
# EXTRACTION SKILLS ENRICHIE
# ========================================

def extract_key_skills_from_job(job_posting_data, job_category):
    """
    VERSION V27.4 : Extraction enrichie avec secteur + certifications
    """
    skills = {
        'tools': [],
        'technical': [],
        'soft': [],
        'certifications': [],
        'sector': 'le secteur',
        'sector_code': 'general',
        'context': []
    }
    
    if not job_posting_data:
        return skills
    
    job_text = f"{job_posting_data.get('title', '')} {job_posting_data.get('description', '')}".lower()
    
    # Ã‰TAPE 1 : DÃ©tection secteur
    skills['sector_code'] = detect_company_sector(job_posting_data)
    
    # Ã‰TAPE 2 : Extraction outils
    extracted = extract_all_keywords_from_job(job_posting_data)
    detected_tools = filter_real_tools(extracted)
    skills['tools'] = detected_tools
    
    # Ã‰TAPE 3 : Certifications et normes
    skills['certifications'] = extract_certifications_and_norms(job_posting_data)
    
    # Ã‰TAPE 4 : CompÃ©tences techniques
    technical_keywords = {
        'consolidation': 'consolidation',
        'ifrs': 'normes IFRS',
        'gaap': 'normes GAAP',
        'sox': 'contrÃ´les SOX',
        'budget': 'budget',
        'forecast': 'forecast',
        'clÃ´ture': 'clÃ´ture',
        'reporting': 'reporting',
        'fp&a': 'FP&A',
        'business partnering': 'business partnering',
        'audit interne': 'audit interne',
        'audit financier': 'audit financier',
        'contrÃ´le interne': 'contrÃ´le interne',
        'trÃ©sorerie': 'trÃ©sorerie',
        'supply chain': 'supply chain',
        'processus opÃ©rationnels': 'processus opÃ©rationnels',
        'comptabilitÃ© technique': 'comptabilitÃ© technique',
        'flux rÃ©assurance': 'flux rÃ©assurance',
        'co-assurance': 'co-assurance',
        'solvabilitÃ©': 'SolvabilitÃ© II'
    }
    
    for keyword, tech_name in technical_keywords.items():
        if keyword in job_text:
            if tech_name not in skills['technical']:
                skills['technical'].append(tech_name)
    
    # Ã‰TAPE 5 : Soft skills
    soft_keywords = {
        'change management': 'change management',
        'conduite du changement': 'conduite du changement',
        'adoption': 'adoption utilisateurs',
        'formation': 'formation',
        'pÃ©dagogie': 'pÃ©dagogie',
        'communication': 'communication',
        'stakeholder': 'stakeholder management',
        'accompagnement': 'accompagnement',
        'acculturation': 'acculturation',
        'agile': 'mÃ©thodologie Agile',
        'scrum': 'Scrum',
        'project management': 'project management',
        'autonomie': 'autonomie',
        'rigueur': 'rigueur',
        'animation': 'animation',
        'encadrement': 'encadrement'
    }
    
    for keyword, soft_name in soft_keywords.items():
        if keyword in job_text:
            if soft_name not in skills['soft']:
                skills['soft'].append(soft_name)
    
    # Ã‰TAPE 6 : Contexte secteur
    sector_contexts = {
        'banking': ('le secteur bancaire', ['environnement bancaire', 'rÃ©glementation bancaire', 'CIB']),
        'insurance': ('l\'assurance', ['compagnie d\'assurance', 'SolvabilitÃ© II', 'environnement rÃ©glementÃ©']),
        'logistics_transport': ('la logistique et le transport', ['supply chain', 'opÃ©rations logistiques', 'rÃ©seau international']),
        'manufacturing': ('l\'industrie', ['sites de production', 'manufacturing', 'environnement industriel']),
        'engineering': ('l\'ingÃ©nierie', ['infrastructure', 'construction', 'projets d\'envergure']),
        'retail': ('le retail', ['rÃ©seau multi-sites', 'distribution']),
        'fintech': ('la fintech', ['startup fintech', 'scale-up', 'innovation financiÃ¨re']),
        'services': ('les services', ['conseil', 'prestations']),
        'gaming': ('le gaming', ['jeu vidÃ©o', 'entertainment', 'revenus rÃ©currents'])
    }
    
    if skills['sector_code'] in sector_contexts:
        skills['sector'], skills['context'] = sector_contexts[skills['sector_code']]
    else:
        skills['sector'] = 'le secteur'
        skills['context'] = ['grand groupe', 'international']
    
    log_event('skills_extracted_v27_4', {
        'tools': skills['tools'],
        'certifications': skills['certifications'],
        'sector': skills['sector_code'],
        'technical_count': len(skills['technical'])
    })
    
    return skills


# ========================================
# FONCTIONS UTILITAIRES
# ========================================

def get_safe_firstname(prospect_data):
    """Trouve le prÃ©nom"""
    target_keys = [
        'first_name', 'firstname', 'first name', 
        'prÃ©nom', 'prenom', 'name',
        'user_first_name', 'user_firstname'
    ]
    
    for key, value in prospect_data.items():
        if str(key).lower().strip() in target_keys:
            if value and str(value).strip():
                return str(value).strip().capitalize()
    
    full_name = prospect_data.get('full_name') or prospect_data.get('user_full name')
    if full_name and ' ' in str(full_name):
        parts = str(full_name).split()
        if len(parts) >= 1:
            return parts[0].capitalize()
    
    return "[PrÃ©nom]"


def get_smart_context(job_posting_data, prospect_data):
    """DÃ©finit le sujet de la discussion"""
    if job_posting_data and job_posting_data.get('title') and len(str(job_posting_data.get('title'))) > 2:
        title = str(job_posting_data.get('title'))
        title = re.sub(r'\s*\(?[HhFf]\s*[/\-]\s*[HhFfMm]\)?', '', title, flags=re.IGNORECASE)
        title = re.sub(r'\s*[-|]\s*.*$', '', title)
        return title.strip().title(), True

    headline = str(prospect_data.get('headline', '')).lower()
    
    if 'financ' in headline or 'daf' in headline or 'cfo' in headline:
        return "vos Ã©quipes Finance", False
    elif 'rh' in headline or 'drh' in headline or 'talents' in headline:
        return "votre stratÃ©gie Talents", False
    elif 'audit' in headline:
        return "votre dÃ©partement Audit", False
    else:
        return "vos Ã©quipes", False


def flexible_match(keyword, text):
    """Match flexible : insensible Ã  la casse, espaces, tirets"""
    pattern = re.escape(keyword).replace(r'\ ', r'[\s\-_]*')
    return bool(re.search(pattern, text, re.IGNORECASE))


# ========================================
# GÃ‰NÃ‰RATEURS DE MESSAGES
# ========================================

def generate_subject_lines(prospect_data, job_posting_data):
    """GÃ©nÃ¨re les objets d'email axÃ©s pain points"""
    
    log_event('generate_subject_lines_start', {
        'prospect': prospect_data.get('_id', 'unknown')
    })
    
    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
    
    context_name, is_hiring = get_smart_context(job_posting_data, prospect_data)
    job_category = detect_job_category(prospect_data, job_posting_data)
    pain_point = get_relevant_pain_point(job_category, job_posting_data)
    
    skills = extract_key_skills_from_job(job_posting_data, job_category)
    detected_keywords = skills['tools'] + skills['technical'][:3] + skills['soft'][:2]
    
    if is_hiring:
        prompt_type = "recrutement actif"
        subject_focus = f"Poste : {context_name}"
    else:
        prompt_type = "approche spontanÃ©e"
        subject_focus = f"Sujet : {context_name}"
    
    job_title = job_posting_data.get('title', 'N/A') if job_posting_data else 'N/A'
    
    prompt = f"""Tu es expert en copywriting B2B pour cabinet de recrutement Finance.

CONTEXTE :
{prompt_type.capitalize()}
{subject_focus}
Entreprise : {prospect_data.get('company', 'l\'entreprise')}
MÃ©tier dÃ©tectÃ© : {job_category}
Secteur : {skills['sector_code']}

MOTS-CLÃ‰S DÃ‰TECTÃ‰S :
{', '.join(detected_keywords[:10]) if detected_keywords else 'Aucun mot-clÃ© spÃ©cifique'}

PAIN POINT :
{pain_point['short']}

CONSIGNE :
GÃ©nÃ¨re 3 objets d'email courts (40-60 caractÃ¨res) :
1. Question avec mot-clÃ© outil/secteur OU pain point
2. Constat marchÃ© avec compÃ©tence spÃ©cifique
3. Objet direct : "Re: [titre poste]"

INTERDICTIONS :
âŒ Pas de "OpportunitÃ©", "Proposition", "Collaboration"
âŒ Pas de points d'exclamation
âŒ Pas de promesses directes

GÃ©nÃ¨re les 3 objets (numÃ©rotÃ©s 1, 2, 3) :"""
    
    try:
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=200,
            messages=[{"role": "user", "content": prompt}]
        )
        
        tracker.track(message.usage, 'generate_subject_lines')
        result = message.content[0].text.strip()
        
        log_event('generate_subject_lines_success', {'length': len(result)})
        return result
        
    except Exception as e:
        log_error('generate_subject_lines_error', str(e), {})
        return f"1. {pain_point['short'][:50]}\n2. {context_name} - Profils qualifiÃ©s\n3. Re: {context_name}"


def generate_message_2(prospect_data, hooks_data, job_posting_data, message_1_content):
    """
    GÃ©nÃ¨re le message 2 avec 2 profils ultra-diffÃ©renciÃ©s
    VERSION V27.5 : Utilise compÃ©tences rares + reformulation obligatoire
    """
    
    log_event('generate_message_2_start', {
        'prospect': prospect_data.get('_id', 'unknown')
    })
    
    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
    
    first_name = get_safe_firstname(prospect_data)
    context_name, is_hiring = get_smart_context(job_posting_data, prospect_data)
    job_category = detect_job_category(prospect_data, job_posting_data)
    pain_point = get_relevant_pain_point(job_category, job_posting_data)
    
    skills = extract_key_skills_from_job(job_posting_data, job_category)
    
    if is_hiring:
        intro_phrase = f"Je me permets de vous relancer concernant votre recherche de {context_name}."
    else:
        intro_phrase = f"Je reviens vers vous concernant la structuration de {context_name}."
    
    # PrÃ©parer outils/certifications
    tools_str = ', '.join(skills['tools'][:5]) if skills['tools'] else 'AUCUN'
    certs_str = ', '.join(skills['certifications']) if skills['certifications'] else 'AUCUNE'
    technical_str = ', '.join(skills['technical'][:5]) if skills['technical'] else 'N/A'
    
    tools_warning = "" if skills['tools'] else "\nâš ï¸ AUCUN OUTIL DÃ‰TECTÃ‰ â†’ NE MENTIONNE AUCUN OUTIL SPÃ‰CIFIQUE"
    cert_warning = "" if skills['certifications'] else "\nâš ï¸ AUCUNE CERTIFICATION â†’ NE MENTIONNE AUCUNE CERTIFICATION"
    
    # CompÃ©tences rares si disponibles
    competences_rares_str = ""
    if pain_point.get('competences_rares'):
        competences_rares_str = f"\nCOMPÃ‰TENCES RARES (Ã  utiliser pour les profils) : {', '.join(pain_point['competences_rares'])}"
    
    # Extraire le texte brut de la fiche
    job_desc_raw = job_posting_data.get('description', '')[:1000] if job_posting_data else ''
    
    # Extraire l'expÃ©rience demandÃ©e si mentionnÃ©e
    exp_match = re.search(r'(\d+)\s*(?:ans?|years?)\s*(?:d\'expÃ©rience|d\'experience|experience|minimum)', job_desc_raw.lower())
    exp_required = f"{exp_match.group(1)} ans" if exp_match else "plusieurs annÃ©es"
    
    prompt = f"""Tu es chasseur de tÃªtes spÃ©cialisÃ© Finance.

CONTEXTE :
Prospect : {first_name}
Poste : {context_name}
MÃ©tier : {job_category}
Secteur : {skills['sector_code']}

EXTRACTION FICHE :
Outils : {tools_str}
Certifications : {certs_str}
CompÃ©tences techniques : {technical_str}
ExpÃ©rience demandÃ©e : {exp_required}
{tools_warning}
{cert_warning}
{competences_rares_str}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TEXTE BRUT DE LA FICHE (RÃ‰FÃ‰RENCE OBLIGATOIRE) :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{job_desc_raw}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš¨ RÃˆGLES ABSOLUES :

1. OBSERVATION MARCHÃ‰ (phrase 3) :
   - DOIT mentionner des termes EXACTS de la fiche ci-dessus
   - NE PAS rÃ©pÃ©ter "rigueur", "agilitÃ©", "dynamique"
   - Exemples de bonnes observations : 
     * "Le dÃ©fi rÃ©side dans la maÃ®trise simultanÃ©e des flux de rÃ©assurance et de coassurance"
     * "Trouver des profils maÃ®trisant Ã  la fois les provisions techniques et les arrÃªtÃ©s trimestriels reste rare"

2. PROFILS (phrases 5-6) :
   - Utiliser les compÃ©tences EXACTES de la fiche
   - Respecter l'expÃ©rience demandÃ©e ({exp_required})
   - Profil 1 : SpÃ©cialiste du secteur avec les compÃ©tences rares
   - Profil 2 : Parcours alternatif (Big 4, reconversion) mais avec compÃ©tences pertinentes
   - JAMAIS inventer "SolvabilitÃ© II", "CIA", etc. si pas dans la fiche

3. Les 2 profils doivent Ãªtre RADICALEMENT DIFFÃ‰RENTS

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
INTERDICTIONS ABSOLUES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âŒ JAMAIS inventer des compÃ©tences/outils/certifications non dans la fiche
âŒ JAMAIS utiliser "rigueur", "agilitÃ©", "dynamisme", "croissance"
âŒ JAMAIS exagÃ©rer l'expÃ©rience (si fiche dit {exp_required}, respecter)
âŒ JAMAIS dire "cabinet d'audit" si la fiche ne demande pas d'expÃ©rience audit

FORMAT (100-120 mots) :
1. "Bonjour {first_name},"
2. "{intro_phrase}"
3. Observation marchÃ© avec VOCABULAIRE EXACT de la fiche (20-25 mots)
4. "J'ai identifiÃ© 2 profils qui pourraient retenir votre attention :"
5. "- L'un [profil 1 spÃ©cialiste avec compÃ©tences EXACTES de la fiche]"
6. "- L'autre [profil 2 parcours alternatif]"
7. "Seriez-vous d'accord pour recevoir leurs synthÃ¨ses anonymisÃ©es ?"
8. "Bien Ã  vous,"

GÃ©nÃ¨re le message :"""
    
    log_event('message_2_prompt_built', {
        'competences_rares': pain_point.get('competences_rares', []),
        'exp_required': exp_required
    })
    
    try:
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1200,
            messages=[{"role": "user", "content": prompt}]
        )
        
        tracker.track(message.usage, 'generate_message_2')
        result = message.content[0].text.strip()
        
        log_event('generate_message_2_success', {'length': len(result)})
        return result
        
    except Exception as e:
        log_error('generate_message_2_error', str(e), {})
        return generate_message_2_fallback(first_name, context_name, is_hiring, 
                                          job_posting_data, skills, pain_point)


def generate_message_2_fallback(first_name, context_name, is_hiring, job_posting_data, skills, pain_point):
    """Fallback intelligent pour Message 2"""
    
    if is_hiring:
        intro = f"Je me permets de vous relancer concernant votre recherche de {context_name}."
    else:
        intro = f"Je reviens vers vous concernant la structuration de {context_name}."
    
    observation = f"Le dÃ©fi principal rÃ©side dans {pain_point['short']}."
    
    tool_1 = skills['tools'][0] if skills['tools'] else 'outils mÃ©tier'
    tech_1 = skills['technical'][0] if skills['technical'] else 'expertise technique'
    soft_1 = skills['soft'][0] if skills['soft'] else 'conduite du changement'
    
    profile_1 = f"- L'un possÃ¨de une expertise {tech_1} avec maÃ®trise de {tool_1}, ayant pilotÃ© des projets de transformation avec forte autonomie."
    profile_2 = f"- L'autre combine expÃ©rience Big 4 et {soft_1}, expert accompagnement d'Ã©quipes et communication transverse."
    
    return f"""Bonjour {first_name},

{intro}

{observation}

J'ai identifiÃ© 2 profils qui pourraient retenir votre attention :
{profile_1}
{profile_2}

Seriez-vous d'accord pour recevoir leurs synthÃ¨ses anonymisÃ©es ? Cela vous permettrait de juger leur pertinence en 30 secondes.

Bien Ã  vous,"""


def generate_message_3(prospect_data, message_1_content, job_posting_data):
    """Message 3 - TEMPLATE FIXE"""
    
    first_name = get_safe_firstname(prospect_data)
    
    return f"""Bonjour {first_name},

Je comprends que vous n'ayez pas eu le temps de revenir vers moi â€” je sais Ã  quel point vos fonctions sont sollicitÃ©es.

Avant de clore le dossier de mon cÃ´tÃ©, une derniÃ¨re question : Est-ce que le timing n'est simplement pas bon pour l'instant, ou bien travaillez-vous dÃ©jÃ  avec d'autres cabinets/recruteurs sur ce poste ?

Si c'est une question de timing, je serai ravi de reprendre contact dans quelques semaines.

Si vous prÃ©fÃ©rez gÃ©rer ce recrutement autrement, aucun souci â€” je vous souhaite de trouver la perle rare rapidement.

Merci en tous cas pour votre attention,

Bonne continuation,"""


# ========================================
# FONCTION PRINCIPALE
# ========================================

def generate_full_sequence(prospect_data, hooks_data, job_posting_data, message_1_content):
    """GÃ©nÃ¨re une sÃ©quence complÃ¨te avec validation"""
    
    log_event('sequence_generation_start', {
        'prospect_id': prospect_data.get('_id', 'unknown'),
        'prospect_name': prospect_data.get('full_name', 'unknown'),
        'company': prospect_data.get('company', 'unknown'),
        'has_job_posting': bool(job_posting_data),
        'has_hooks': hooks_data != "NOT_FOUND"
    })
    
    try:
        subject_lines = generate_subject_lines(prospect_data, job_posting_data)
        message_2 = generate_message_2(prospect_data, hooks_data, job_posting_data, message_1_content)
        message_3 = generate_message_3(prospect_data, message_1_content, job_posting_data)
        
        sequence = {
            'subject_lines': subject_lines,
            'message_1': message_1_content,
            'message_2': message_2,
            'message_3': message_3
        }
        
        is_valid = validate_and_report(sequence, prospect_data, raise_on_error=False)
        
        log_event('sequence_generation_success', {
            'prospect_id': prospect_data.get('_id', 'unknown'),
            'valid': is_valid
        })
        
        return sequence
        
    except Exception as e:
        log_error('sequence_generation_failed', str(e), {
            'prospect_id': prospect_data.get('_id', 'unknown')
        })
        raise
